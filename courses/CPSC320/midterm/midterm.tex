\documentclass[conference]{IEEEtran}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath, amsfonts, amssymb, ragged2e}
\usepackage{amsthm}
% \usepackage{algpseudocode}
% \usepackage{comment}



\newtheorem*{theorem}{Theorem}
\newtheorem*{definition}{Definition}
\newtheorem*{corollary}{Corollary}
\newtheorem*{lemma}{Lemma}
\newtheorem*{proposition}{Proposition}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\setcounter{MaxMatrixCols}{12} % increase maximum matrix width
\begin{document}


\section{Geometric Series}
\begin{align*}
    \sum_{k=0}a r^k &= a (\frac{1-r^{n+1}}{1-r})\\
    & = \frac{a}{1-r} \forall |r| < 1
\end{align*}
\section{SMP}
It is always true that employers with the same preferences will have the same stable matching.\begin{proof}
    Prove inductively, remove the most stable pair, then the remaining employers and employees have the same preferences. Continue until all pairs are removed.
\end{proof}
\section{Asymptotic}
log $<$ polynomial $<$ exponential $<$ factorial
\section{Greedy Algorithms}
Chase only the local optimum, not the global optimum.
\subsection{Greedy stays ahead}

    If a greedy algorithm always makes a choice that stays ahead (at least as good) of the optimal solution, then the greedy algorithm is optimal.

    Inductively show that at each stage, the greedy solution is at least as good as the optimal solution.

\section{Divide and Conquer}
Divide the input into smaller instances (subproblems), solve recursively, then combine to get the solution.

\subsection{Recurrence Relations}
\subsubsection{Recurrence Tree}
Each level of the tree represents the cost of the work done at that level. The total cost is the sum of the costs at each level. Usually $\log n$ levels with a $f(n)$ cost at each level.
\subsubsection{Master Theorem}
Let $a \geq 1$ and $b > 1$ be constants, let $f(n)$ be a function, and let $T(n)$ be defined on the non-negative integers by the recurrence relation: \[
    T(n) = aT(n/b) + f(n)
\]
where $n/b$ means either $\lfloor n/b \rfloor$ or $\lceil n/b \rceil$. Then $T(n)$ has the following asymptotic bounds: \begin{enumerate}
    \item If $f(n) = O(n^{\log_b a - \epsilon})$ for some constant $\epsilon > 0$, then $T(n) = \Theta(n^{\log_b a})$.
    \item If $f(n) = \Theta(n^{\log_b a} \log^k n)$, then $T(n) = \Theta(n^{\log_b a} \log^{k+1} n)$.
    \item If $f(n) = \Omega(n^{\log_b a + \epsilon})$ for some constant $\epsilon > 0$, and if $a f(n/b) \leq k f(n)$ for some constant $k < 1$ and sufficiently large $n$, then $T(n) = \Theta(f(n))$.
\end{enumerate}

\subsection{Prune and Search}

\begin{definition}
    \textbf{Prune and Search} is a problem-solving strategy that divides the search space into two parts, one of which is pruned (discarded) and the other is searched.
\end{definition}

To find the $k$th smallest element in an array, we can use the QuickSelect algorithm. The algorithm is as follows:
\begin{enumerate}
    \item Function{QuickSelect}{$(A[1:n], k)$}
    \item If $n = 1$ return $A[1]$
    \item Choose a random pivot element $p$ from $A$
    \item Partition $A$ into $L = \{x \in A : x < p\}$, $E = \{x \in A : x = p\}$, $G = \{x \in A : x > p\}$
    \item If $k \leq |L|$, return QuickSelect$(L, k)$
    \item Else if $k \leq |L| + |E|$, return $p$
    \item Else return QuickSelect$(G, k - |L| - |E|)$
    \item End Function
\end{enumerate}
\section{Dynamic Programming}

Typical DP examples: \[
    \text{DP}[i] = \begin{cases}
        \text{base case} & \text{start} \\
        \text{combine}(\text{DP}[i-1], \text{DP}[i-2], \ldots, \text{DP}[i-k]) & \text{otherwise}
    \end{cases}
\]

Or \[
    \text{OPT}(j) = \max \{ \text{OPT}(j-1), \text{OPT}(j-2) + v_j \}
\]
Iterative starts with the base case and builds up to the solution. Recursive starts with the solution and breaks it down to the base case.

\section{NP-Completeness}
As long as the algorithm runs in $O(n^k)$ time, it is considered polynomial time. We think it is efficient.

\subsection{Decision V.S. Optimization}
\begin{definition}
    Optimization problem: we want to find the solution $s$ that maximizes or minimizes some objective function $f(s)$.
\end{definition}
\begin{definition}
    Decision problem: given a parameter $k$, we want to know if there is a solution $s$ such that $f(s) \geq k$ (maximization) or $f(s) \leq k$ (minimization).
\end{definition}
\subsection{P and NP}
\begin{definition}
    \textbf{P} is the class of decision problems that can be solved in polynomial time. (We have the solver)
\end{definition}
\begin{definition}
    \textbf{NP} is the class of decision problems for which a solution can be verified in polynomial time. (We have the verifier)
\end{definition}
\subsection{Proof of NP-completeness}
\begin{enumerate}
    \item Show that the problem is in NP.
    \item Show that the problem is in NP-hard.
\end{enumerate}
\subsubsection{Proof of NP}
To prove that P is in NP, we need to \textbf{efficiently verify} a \textbf{certificate}.\begin{itemize}
    \item A certificate is a proof that the solution is correct.
    \item A verifier is an algorithm that checks the certificate. Needs to run in polynomial time.
    \item For example, an optimization problem can be: Does there exists $X$ such that $Y$ is true?\begin{itemize}
        \item $X$ is the certificate.
        \item $Y$ is the verifier.
    \end{itemize}
\end{itemize}
\subsubsection{Proof of NP-hard}
\begin{definition}
    A problem $A$ is \textbf{NP-hard} if $P$ is at least as hard as any other problem in NP.
\end{definition}
We prove ``at least as hard'' via polynomial-time reduction. 
\begin{itemize}
    \item Pick a known NP-complete problem $B$. Let $A$ be the problem we want to prove is NP-hard.
    \item Show that $B$ can be reduced to $A$ in polynomial time with the same YES/NO answer.
    \item Since $B$ is NP-complete, $A$ is NP-hard.
    \item Intuition: Since we can use a solver for $A$ to solve $B$, this tells us that $A$ is at least as hard as $B$ (It is powerful enough to handle $B$)
\end{itemize}


% \begin{algorithmic}
%     \Function{QuickSelect}{$A[1:n], k$} \Comment{ Returns the element of rank k in an array of n numbers}
%     \If {n = 1}
%         \State \Return A[1]
%     \EndIf
%     \State Choose a random pivot element p from A
%     \State Partition A into $L = \{x \in A : x < p\}$, $E = \{x \in A : x = p\}$, $G = \{x \in A : x > p\}$
%     \If {k $\leq |L|$}
%         \State \Return QuickSelect(L, k)
%     \ElsIf {k $\leq |L| + |E|$}
%         \State \Return p
%     \Else
%         \State \Return QuickSelect(G, k - |L| - |E|)
%     \EndIf
%     \EndFunction
% \end{algorithmic}

% \begin{algorithm}
%     \begin{algorithmic}
%         \Function{QuickSelect}{$A[1:n], k$} \Comment{ Returns the element of rank k in an array of n numbers}
%         \If {n = 1}
%             \State \Return A[1]
%         \EndIf
%         \State Choose a random pivot element p from A
%         \State Partition A into $L = \{x \in A : x < p\}$, $E = \{x \in A : x = p\}$, $G = \{x \in A : x > p\}$
%         \If {k $\leq |L|$}
%             \State \Return QuickSelect(L, k)
%         \ElsIf {k $\leq |L| + |E|$}
%             \State \Return p
%         \Else
%             \State \Return QuickSelect(G, k - |L| - |E|)
%         \EndIf
%         \EndFunction
%     \end{algorithmic}
%   \end{algorithm}


\end{document}