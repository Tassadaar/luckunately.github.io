{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my work for CPEN 355 projects. If you change the directory in the methods such that you have all the songs labeled, it should just run directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction:\n",
    "\n",
    "Take start, middle, end snipet of 10s, break them down into even smaller number, find the FFT number of each interested frequency. Maybe compress it to reduce burden? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the linraries I want to use  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eyed3\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import os\n",
    "#import audio2numpy as a2n\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal approach of analyzing a audio file might need to apply FFT from 20Hz to 20000Hz (The sound range of most humans). For this project, to save my GPU's life, I will just check for the most used notes with the respected frequency. \n",
    "\n",
    "Not checking the frequencies between the notes would eliminate some information but that should not be a major issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store musical notes and their frequencies\n",
    "musical_notes = {\n",
    "    'A1': 55.0,\n",
    "    'A#1/Bb1': 58.27,\n",
    "    'B1': 61.74,\n",
    "    'C2': 65.41,\n",
    "    'C#2/Db2': 69.3,\n",
    "    'D2': 73.42,\n",
    "    'D#2/Eb2': 77.78,\n",
    "    'E2': 82.41,\n",
    "    'F2': 87.31,\n",
    "    'F#2/Gb2': 92.5,\n",
    "    'G2': 98.0,\n",
    "    'G#2/Ab2': 103.83,\n",
    "    'A2': 110.0,\n",
    "    'A#2/Bb2': 116.54,\n",
    "    'B2': 123.47,\n",
    "    'C3': 130.81,\n",
    "    'C#3/Db3': 138.59,\n",
    "    'D3': 146.83,\n",
    "    'D#3/Eb3': 155.56,\n",
    "    'E3': 164.81,\n",
    "    'F3': 174.61,\n",
    "    'F#3/Gb3': 185.0,\n",
    "    'G3': 196.0,\n",
    "    'G#3/Ab3': 207.65,\n",
    "    'A3': 220.0,\n",
    "    'A#3/Bb3': 233.08,\n",
    "    'B3': 246.94,\n",
    "    'C4': 261.63,\n",
    "    'C#4/Db4': 277.18,\n",
    "    'D4': 293.66,\n",
    "    'D#4/Eb4': 311.13,\n",
    "    'E4': 329.63,\n",
    "    'F4': 349.23,\n",
    "    'F#4/Gb4': 369.99,\n",
    "    'G4': 392.0,\n",
    "    'G#4/Ab4': 415.3,\n",
    "    'A4': 440.0,\n",
    "    'A#4/Bb4': 466.16,\n",
    "    'B4': 493.88,\n",
    "    'C5': 523.25,\n",
    "    'C#5/Db5': 554.37,\n",
    "    'D5': 587.33,\n",
    "    'D#5/Eb5': 622.25,\n",
    "    'E5': 659.26,\n",
    "    'F5': 698.46,\n",
    "    'F#5/Gb5': 739.99,\n",
    "    'G5': 783.99,\n",
    "    'G#5/Ab5': 830.61,\n",
    "    'A5': 880.0,\n",
    "    'A#5/Bb5': 932.33,\n",
    "    'B5': 987.77,\n",
    "    'C6': 1046.5,\n",
    "    'C#6/Db6': 1108.73,\n",
    "    'D6': 1174.66,\n",
    "    'D#6/Eb6': 1244.51,\n",
    "    'E6': 1318.51,\n",
    "    'F6': 1396.91,\n",
    "    'F#6/Gb6': 1479.98,\n",
    "    'G6': 1567.98,\n",
    "    'G#6/Ab6': 1661.22,\n",
    "    'A6': 1760.0,\n",
    "    'A#6/Bb6': 1864.66,\n",
    "    'B6': 1975.53,\n",
    "    'C7': 2093.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write methods to read MP3 file\n",
    "\n",
    "read_mp3_songs(path): finds all the mp3 files and keep their address\n",
    "\n",
    "get_mp3_info(mp3_filename): finds the start middle and end 10s of snipets. (Again not analyzing the whole song to save my computer)\n",
    "\n",
    "get_mp3_info(mp3_filename): finds the artist and song name. (Supervised Learning purpose)\n",
    "\n",
    "calculate_fft(segment, sampling_rate): FFT function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the artist and title info\n",
    "def get_mp3_info(mp3_filename):\n",
    "    # Initialize Eyed3\n",
    "    audiofile = eyed3.load(mp3_filename)\n",
    "\n",
    "    # Get artist and genre from the MP3 file's metadata\n",
    "    artist = audiofile.tag.artist\n",
    "    #genre = audiofile.tag.genre.name\n",
    "    title = audiofile.tag.title\n",
    "\n",
    "    return artist, title\n",
    "\n",
    "# Function to get snippets of start mid and end 10s. Then apply FFT to get interested frequency data, store them into seprate .csv files. \n",
    "# Note that for start and end, I skipped 10s since usually they do not contain information\n",
    "def generate_audio_snippets(mp3_filename):\n",
    "    \n",
    "    # Check if it is unlabeld. \n",
    "    artist, title = get_mp3_info(mp3_filename)\n",
    "    if title == None:\n",
    "        title = os.path.basename(mp3_filename)\n",
    "    if artist == None:\n",
    "        artist = 'unkown'\n",
    "    output_file_path = os.path.dirname(mp3_filename)\n",
    "    \n",
    "    # If the file already exists, skip it\n",
    "    if os.path.exists(output_file_path + '\\start\\\\' + title + '.csv'):\n",
    "        return\n",
    "    \n",
    "    # Load the MP3 file\n",
    "    print(mp3_filename)\n",
    "    mp3_file, sampling_rate = librosa.load(mp3_filename)\n",
    "    \n",
    "    \n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(output_file_path + '\\start'):\n",
    "        # If it doesn't exist, create the folder\n",
    "        os.makedirs(output_file_path + '\\start')\n",
    "        os.makedirs(output_file_path + '\\mid')\n",
    "        os.makedirs(output_file_path + '\\end')\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "    # Calculate the start and end points for the 10-second snippets\n",
    "    duration = 10 * sampling_rate  # 10 seconds of samples\n",
    "    center = len(mp3_file) // 2  # Calculate the center of the audio\n",
    "\n",
    "    # Start and end times for snippets\n",
    "    start_times = [duration, center - duration // 2, len(mp3_file) - duration * 2]\n",
    "    end_times = [duration * 2, center + duration // 2, len(mp3_file) - duration]\n",
    "    start, mid, end = [],[],[]\n",
    "    \n",
    "    start = mp3_file[start_times[0]:end_times[0]]\n",
    "    mid = mp3_file[start_times[1]:end_times[1]]\n",
    "    end = mp3_file[start_times[2]:end_times[2]]\n",
    "    \n",
    "    # Normalize the audio data to the range [-1, 1]\n",
    "    start = 2 * (start - min(start)) / (max(start) - min(start)) - 1\n",
    "    mid = 2 * (mid - min(mid)) / (max(mid) - min(mid)) - 1\n",
    "    end = 2 * (end - min(end)) / (max(end) - min(end)) - 1\n",
    "    \n",
    "    # Calculate the number of samples per chunk\n",
    "    chunk_duration = 0.08  # in seconds\n",
    "    samples_per_chunk = int(sampling_rate * chunk_duration)\n",
    "    \n",
    "    # Extract chunks and apply FFT\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, len(start) - samples_per_chunk, samples_per_chunk):\n",
    "        chunk = start[i:i + samples_per_chunk]\n",
    "        fft_result = calculate_fft(chunk, sampling_rate)\n",
    "        results.append(fft_result)\n",
    "        \n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    csv_path = output_file_path + '\\start\\\\' + title + '.csv'\n",
    "    # Save the DataFrame to a new CSV file\n",
    "    with open(csv_path, 'w', newline='') as csv_file:\n",
    "        df_results.to_csv(csv_path, index=False)\n",
    "      \n",
    "    # Time for mid  \n",
    "    results.clear\n",
    "    \n",
    "    for i in range(0, len(start) - samples_per_chunk, samples_per_chunk):\n",
    "        chunk = mid[i:i + samples_per_chunk]\n",
    "        fft_result = calculate_fft(chunk, sampling_rate)\n",
    "        results.append(fft_result)\n",
    "    \n",
    "    csv_path = output_file_path + '\\mid\\\\' + title + '.csv'    \n",
    "    # Save the DataFrame to a new CSV file\n",
    "    with open(csv_path, 'w', newline='') as csv_file:\n",
    "        df_results.to_csv(csv_path, index=False)\n",
    "       \n",
    "    # Time for end \n",
    "    results.clear\n",
    "    \n",
    "    for i in range(0, len(start) - samples_per_chunk, samples_per_chunk):\n",
    "        chunk = end[i:i + samples_per_chunk]\n",
    "        fft_result = calculate_fft(chunk, sampling_rate)\n",
    "        results.append(fft_result)\n",
    "    \n",
    "    csv_path = output_file_path + '\\end\\\\' + title + '.csv'\n",
    "    # Save the DataFrame to a new CSV file\n",
    "    with open(csv_path, 'w', newline='') as csv_file:\n",
    "        df_results.to_csv(csv_path, index=False)\n",
    "    \n",
    "    return\n",
    "\n",
    "# Function to get all paths for my mp3 files\n",
    "def read_mp3_songs(path):\n",
    "    # Get the path of all songs given the song foler.\n",
    "    # Checks each foler in the given folder. \n",
    "    mp3_songs = []\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".mp3\"):\n",
    "                mp3_path = os.path.join(root, file)\n",
    "                mp3_songs.append(mp3_path)\n",
    "\n",
    "    return mp3_songs\n",
    "\n",
    "# Function to calculate FFT and extract amplitudes for musical notes\n",
    "def calculate_fft(segment, sampling_rate):\n",
    "    fft_result = np.fft.fft(segment)\n",
    "    frequencies = np.fft.fftfreq(len(segment), d=1/sampling_rate)\n",
    "    \n",
    "    # Dictionary to store amplitude for each musical note\n",
    "    amplitudes = {note: np.abs(fft_result[np.abs(frequencies - freq).argmin()]) for note, freq in musical_notes.items()}\n",
    "    \n",
    "    return amplitudes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lame tag CRC check failed\n",
      "Invalid numeric genre ID: 255\n",
      "Unknown genre ID: 255\n",
      "Invalid numeric genre ID: 255\n",
      "Unknown genre ID: 255\n",
      "Invalid numeric genre ID: 255\n",
      "Unknown genre ID: 255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating .csv file\n",
      "218\n"
     ]
    }
   ],
   "source": [
    "\n",
    "songs_path = r\"G:\\Songs\"  # Where I store files\n",
    "\n",
    "mp3_songs = read_mp3_songs(songs_path) # Now all mp3 file path are in here\n",
    "count = 0\n",
    "\n",
    "# Now all data in .csv I can start machine learning. Once they are in there, I do not need to regenerate the analyzed data anymore. \n",
    "for mp3_path in mp3_songs:\n",
    "    count = count + 1\n",
    "    generate_audio_snippets(mp3_path)\n",
    "    \n",
    "print(\"Finished generating .csv file\")\n",
    "print(str(count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training start, to further save my computer, I use PCA to reduce dimensionality:\n",
    "\n",
    "To decide how many components I want to use, I pull out a sigle file and calculate it with different components and test for the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 124)\n",
      "5 0.7622643349134097\n",
      "10 0.8900002447246864\n",
      "15 0.9469214522773146\n",
      "20 0.9747891903428441\n",
      "25 0.9878881694342643\n",
      "30 0.9938506035941943\n",
      "35 0.9970978976930218\n",
      "40 0.9989502181218164\n",
      "45 0.9997231555562979\n",
      "50 0.9999554205415617\n",
      "55 1.0\n",
      "(64, 10)\n",
      "[[-6.47276460e+01 -4.52118112e+01 -8.17700298e-01 -2.36790238e+01\n",
      "   8.36172925e-01 -1.32682259e+01 -8.30046453e+00 -1.82569662e+00\n",
      "  -7.03011194e+00  9.05113930e+00]\n",
      " [-5.98627802e+01 -3.08017412e+01 -1.07474558e+01 -1.43085606e+01\n",
      "  -5.77663421e+00 -1.75566864e+01 -2.33456976e+00 -8.02911719e-01\n",
      "  -1.35918023e+01  7.84007166e+00]\n",
      " [-5.98627802e+01 -3.08017412e+01 -1.07474558e+01 -1.43085606e+01\n",
      "  -5.77663421e+00 -1.75566864e+01 -2.33456976e+00 -8.02911719e-01\n",
      "  -1.35918023e+01  7.84007166e+00]\n",
      " [-5.98627802e+01 -3.08017412e+01 -1.07474558e+01 -1.43085606e+01\n",
      "  -5.77663421e+00 -1.75566864e+01 -2.33456976e+00 -8.02911719e-01\n",
      "  -1.35918023e+01  7.84007166e+00]\n",
      " [-3.32215318e+01  7.75152264e+01 -1.87871254e+01  1.64132110e+01\n",
      "  -4.91307213e+01 -1.15038126e+02  8.64574461e+00 -1.05930136e+01\n",
      "  -3.06131905e+01 -2.69884169e+01]\n",
      " [-3.32215318e+01  7.75152264e+01 -1.87871254e+01  1.64132110e+01\n",
      "  -4.91307213e+01 -1.15038126e+02  8.64574461e+00 -1.05930136e+01\n",
      "  -3.06131905e+01 -2.69884169e+01]\n",
      " [-3.32215318e+01  7.75152264e+01 -1.87871254e+01  1.64132110e+01\n",
      "  -4.91307213e+01 -1.15038126e+02  8.64574461e+00 -1.05930136e+01\n",
      "  -3.06131905e+01 -2.69884169e+01]\n",
      " [ 7.37436470e+01  1.65744217e+01 -7.41585331e+01 -1.95927807e+01\n",
      "   5.99280409e+01 -2.87323101e+00  2.22268326e+01 -5.68838898e+01\n",
      "   5.27134530e+01 -1.42901714e+01]\n",
      " [ 7.37436470e+01  1.65744217e+01 -7.41585331e+01 -1.95927807e+01\n",
      "   5.99280409e+01 -2.87323101e+00  2.22268326e+01 -5.68838898e+01\n",
      "   5.27134530e+01 -1.42901714e+01]\n",
      " [ 7.37436470e+01  1.65744217e+01 -7.41585331e+01 -1.95927807e+01\n",
      "   5.99280409e+01 -2.87323101e+00  2.22268326e+01 -5.68838898e+01\n",
      "   5.27134530e+01 -1.42901714e+01]\n",
      " [-3.14795987e+01 -9.77295679e-01 -7.15331222e+01  4.78353272e+01\n",
      "  -1.22943167e+01  1.54421763e+01  8.37201124e+01  4.59269726e+01\n",
      "  -5.88349198e+01 -1.99040843e+01]\n",
      " [-3.14795987e+01 -9.77295679e-01 -7.15331222e+01  4.78353272e+01\n",
      "  -1.22943167e+01  1.54421763e+01  8.37201124e+01  4.59269726e+01\n",
      "  -5.88349198e+01 -1.99040843e+01]\n",
      " [-3.47057663e+01  8.95832367e+00 -3.10104628e+01  8.03513977e+00\n",
      "  -1.24025755e+00 -3.68686269e+01  1.43328122e+01 -7.60957160e+00\n",
      "  -9.77310620e+00 -5.05217750e+00]\n",
      " [-3.47057663e+01  8.95832367e+00 -3.10104628e+01  8.03513977e+00\n",
      "  -1.24025755e+00 -3.68686269e+01  1.43328122e+01 -7.60957160e+00\n",
      "  -9.77310620e+00 -5.05217750e+00]\n",
      " [ 2.26388880e+01  2.02236016e+01 -5.70241913e+01  2.14092313e+01\n",
      "   4.93399505e+01 -2.00419232e+01  3.86238114e+01 -2.96355971e+01\n",
      "   6.04141752e+01 -2.29017537e+01]\n",
      " [ 2.26388880e+01  2.02236016e+01 -5.70241913e+01  2.14092313e+01\n",
      "   4.93399505e+01 -2.00419232e+01  3.86238114e+01 -2.96355971e+01\n",
      "   6.04141752e+01 -2.29017537e+01]\n",
      " [ 2.54082414e+01  2.23881291e+01 -7.62653472e+01  3.96052798e+01\n",
      "   3.78392983e+01  1.50094045e+01  5.57946408e+01  9.68376304e+00\n",
      "   2.19461555e+01 -3.55116828e+00]\n",
      " [-3.10801872e+01  7.09332109e+00 -1.27310080e+01 -3.87307893e+00\n",
      "   6.79090615e+00 -8.05381617e+00  9.95263109e+00  4.46111511e+00\n",
      "   6.87706401e+00 -5.54019401e+00]\n",
      " [-3.10801872e+01  7.09332109e+00 -1.27310080e+01 -3.87307893e+00\n",
      "   6.79090615e+00 -8.05381617e+00  9.95263109e+00  4.46111511e+00\n",
      "   6.87706401e+00 -5.54019401e+00]\n",
      " [-3.79328743e+01 -3.64043558e+00 -1.52558764e+01 -4.19236553e-01\n",
      "   3.24823301e+00 -1.78328215e+00  1.21992546e+01  4.89704495e+00\n",
      "  -1.24661135e+01  4.35522482e-01]\n",
      " [ 5.74556512e+00  6.79921266e-01 -5.18808638e+01  1.36982024e+01\n",
      "   7.65535584e+00  3.41323563e+01  3.62104850e+01  1.37957965e+01\n",
      "  -3.15809871e+01  3.90456858e+00]\n",
      " [-2.91780813e+01  1.95001601e+01 -2.40848017e+01  1.12763428e+01\n",
      "  -2.18316045e+01 -5.43153377e+00 -1.36738068e+01 -1.20969408e+01\n",
      "  -1.12929499e+01  2.63534688e+01]\n",
      " [ 2.80446564e+01  1.38327735e+02 -1.17313507e+02  1.13426136e+02\n",
      "  -1.05321201e+02  2.46703310e+01 -3.67038145e+01 -4.10884313e+01\n",
      "   1.18611846e+00  1.31127729e+02]\n",
      " [ 3.78256891e+01  1.23263005e+02 -1.22194567e+02  1.27323582e+02\n",
      "  -7.68489769e+01  1.19093067e+02 -4.73593336e+01 -1.62684244e+00\n",
      "   2.40823667e+01 -5.40814493e+01]\n",
      " [ 3.16297740e+01  2.12184900e+02  4.56346113e+01  1.29142327e+01\n",
      "  -2.45085504e+01 -1.08132343e+01 -4.44019091e+01 -2.06263183e+01\n",
      "   2.45029748e+01  1.16736636e+01]\n",
      " [ 8.27017480e+01  3.43992037e+02  1.00244658e+02 -2.08632101e+00\n",
      "   1.22849898e+01 -6.02756896e+01 -3.59120617e+01  5.13588786e+01\n",
      "  -8.65827702e-01 -3.15749493e+01]\n",
      " [ 2.34372770e+02  1.17490097e+02 -3.55226033e+01 -4.37067236e+01\n",
      "   1.54566865e+02 -1.16815432e+01 -7.43694060e+01  1.13195131e+02\n",
      "   1.43540219e+01  1.33505342e+01]\n",
      " [ 8.67060927e+02 -9.04039482e+01 -1.29112794e+01 -1.40740469e+02\n",
      "  -9.15281805e+01  4.91547701e+00 -1.58638364e+01 -3.75974427e+01\n",
      "  -4.00238320e+01 -1.52568474e+01]\n",
      " [ 1.75416125e+02  2.56441637e+01 -9.96323117e+01  8.03943994e+00\n",
      "   9.18014030e+01  5.45293407e+01  4.24130673e+01  5.50793892e+01\n",
      "  -5.59967352e+01  6.44296646e+01]\n",
      " [ 1.01701329e+01 -2.01085501e+01 -1.41734692e+01 -2.72753179e+01\n",
      "   2.66715433e+01  3.89966293e+00 -9.62553146e+00  1.43746552e+01\n",
      "  -6.77075550e+00  1.51573786e+01]\n",
      " [-2.99007921e+01  1.89696845e+00 -1.88427200e+01 -1.31532097e+01\n",
      "  -8.71156542e+00 -2.10729447e+01  1.78817187e+00  8.60858336e+00\n",
      "  -2.96571570e+01  5.16054252e+00]\n",
      " [-4.76383844e+01 -3.91567365e+01  1.69760845e+00 -2.92346295e+01\n",
      "   1.14430114e+01  1.86650661e+00 -1.11025464e+01  5.11736448e+00\n",
      "  -6.58189851e+00  8.79789509e+00]\n",
      " [-2.83212358e+01 -3.03850661e+01 -1.12540449e+01 -2.10616697e+01\n",
      "   8.03710048e+00  3.41600629e-01 -4.42436288e+00 -1.46398511e+00\n",
      "  -3.59467723e+00  6.08787562e+00]\n",
      " [-5.79168182e+01 -3.51774988e+01  1.88712602e+00 -2.12143662e+01\n",
      "   5.78082652e-01 -2.72303013e+00 -1.75830687e+01 -1.98884001e+00\n",
      "  -1.28853787e+00  1.19348104e+01]\n",
      " [-4.56737420e+01  1.02131471e+01 -4.01180746e+00 -2.20888849e+00\n",
      "  -1.88400568e+01 -3.40094166e+01 -3.17655161e+01 -1.73008379e+01\n",
      "  -1.01885347e+00  2.10612566e+01]\n",
      " [-3.16848063e+01 -1.21428700e+01 -3.08425881e+01  3.33149948e+01\n",
      "  -2.66792134e+01  6.46073753e+01 -4.34721217e+01 -9.02165322e+00\n",
      "   1.31790930e+01 -4.28597832e+00]\n",
      " [-4.82351058e+01 -1.08182724e+01  2.23858112e+01 -1.07215149e+01\n",
      "   8.84907209e+00  1.03867310e+01 -2.01487391e+01 -5.56599512e+00\n",
      "   1.16908848e+01  8.29024230e+00]\n",
      " [-2.38217010e+01  2.02775006e+02  1.85513474e+02 -4.82275146e+01\n",
      "  -8.33767651e-01  7.73756926e+01  1.64611060e+01 -2.17687631e+01\n",
      "   1.73787293e+01  1.57956134e+01]\n",
      " [-1.03332834e-01 -2.61770972e+01  4.50807606e+01  1.54486986e+01\n",
      "   4.56211828e+01 -1.14463287e+00 -2.09531592e+01  1.45605166e+01\n",
      "   1.48126661e+01 -6.99344273e-01]\n",
      " [ 2.97702976e+02 -1.35420692e+02  2.11897469e+02  2.87026460e+02\n",
      "   7.95957286e+01 -2.84762548e+01 -4.73921933e+00 -3.12240613e+01\n",
      "  -2.43103038e+01  1.60963432e+00]\n",
      " [-4.81000266e+00 -5.53262758e+01  2.76203342e+01  2.68385918e+01\n",
      "   2.74032142e+01  1.10064232e+01  1.72233199e+01 -9.84962316e+00\n",
      "  -1.53696213e+00  1.21735347e+01]\n",
      " [-5.67510746e+01 -4.43556473e+01  1.81571999e+01 -1.15394047e+01\n",
      "  -1.83091251e+00 -4.21801829e+00 -1.95008674e+01 -4.66035027e+00\n",
      "  -4.12317889e+00  9.04252832e+00]\n",
      " [-4.37835558e+01 -3.55381268e+01 -2.29879909e+01  3.17975589e+01\n",
      "  -4.18745621e+01  9.25368338e+01 -5.65665532e+01  2.50535014e+01\n",
      "  -1.98901311e+01 -8.59285714e+01]\n",
      " [-6.45295551e+01 -4.26588895e+01  2.37369604e+01 -2.64247578e+01\n",
      "   1.53765131e+00  1.00402560e+01 -6.97648232e+00 -1.69688509e+00\n",
      "   3.28966909e+00  3.25498079e+00]\n",
      " [-2.54212163e+01  1.59009710e+02  1.56862379e+02 -6.87383111e+01\n",
      "  -1.30737007e+01  1.05869904e+02  1.17863498e+02 -3.77118957e+01\n",
      "  -3.00683028e+01 -5.23242292e+00]\n",
      " [-5.46999809e+01 -2.62649927e+01  3.10637960e+01 -3.01282435e+01\n",
      "   7.46095328e+00 -2.97115234e+00 -1.86843443e+01  3.57378284e+01\n",
      "   1.08299493e+01  1.07033531e+00]\n",
      " [ 1.35644384e+02 -1.09103598e+02  7.52306053e+01  2.24319963e+01\n",
      "  -1.46573703e+02 -3.46438352e+01  8.03176193e+01  1.15588227e+02\n",
      "   1.36214056e+02  2.66949034e+01]\n",
      " [-4.69313392e+01 -4.85909341e+01 -1.27716259e+01  1.52337104e+01\n",
      "  -3.65368078e+01  5.69876960e+01 -4.27759175e+01  2.63065198e+01\n",
      "   1.08844676e+01 -3.76742258e+01]\n",
      " [-6.42708402e+01 -5.39052191e+01  9.10180835e+00 -2.17476903e+01\n",
      "   4.52759311e+00  2.24655145e+00 -3.09918057e+00  5.84847280e-01\n",
      "   3.73540758e+00  7.32078952e+00]\n",
      " [-6.77045060e+01 -2.83893481e+00  5.13597542e+01 -3.54296335e+01\n",
      "  -4.30459637e+00  1.57436684e+01  7.98168879e+00 -8.76671458e-01\n",
      "  -1.16899851e+01  5.26511186e+00]\n",
      " [-6.95907586e+01 -4.06750220e+01  1.48954235e+01 -2.50912564e+01\n",
      "  -7.27709501e-01 -4.75172719e+00 -1.93158371e+01  4.81976036e+00\n",
      "  -1.94017061e+00  7.53636206e+00]\n",
      " [ 3.09827941e+01 -8.30131567e+01  5.69428556e+01  5.09038468e+01\n",
      "  -6.34001669e+00  1.62545546e+01 -1.03700254e+01  5.00101111e+00\n",
      "  -4.43436034e-01 -1.73234639e+01]\n",
      " [-7.26918365e+01 -5.62772331e+01  2.15957737e+01 -2.77045767e+01\n",
      "   3.84073258e+00 -4.15011027e-01 -1.12972296e+01 -2.94197708e+00\n",
      "  -9.72229963e-01  8.20290478e+00]\n",
      " [-7.31095081e+01 -3.71450886e+01  3.41194454e+01 -3.43592919e+01\n",
      "   4.04079786e-01  4.93285590e+00  7.77623246e-01 -7.80760175e+00\n",
      "  -5.12483968e+00  6.38695135e+00]\n",
      " [-7.26342218e+01 -5.94928342e+01  9.10753325e+00 -1.71939936e+01\n",
      "  -4.93983859e+00  1.46141177e+01 -2.54755017e+01  1.33356687e+00\n",
      "  -2.84050691e+00 -9.54997656e+00]\n",
      " [-2.58424442e+01 -7.23664591e+01  3.88461564e+01  1.72960498e+01\n",
      "   1.99410396e+01 -1.02380166e+01 -1.15663276e+01 -1.63931370e+01\n",
      "  -9.80882280e+00  5.28534255e+00]\n",
      " [-7.51845815e+01 -9.04482317e+00  5.91443527e+01 -4.43406438e+01\n",
      "  -6.99132805e+00  3.19382449e+01  6.19832902e+00 -1.25409007e+01\n",
      "  -8.87578007e+00  1.25344372e+01]\n",
      " [-7.88093482e+01 -5.95599804e+01  7.43112526e+00 -2.82216716e+01\n",
      "  -1.48002308e+00  3.93010554e+00 -2.18817160e+01  7.88121289e-02\n",
      "   1.99458453e+00  6.63894467e-02]\n",
      " [-4.62504548e+01 -7.47417548e+01  2.74558790e+01 -6.70195730e+00\n",
      "   7.89024147e+00 -9.25084709e+00 -1.45944289e+01 -1.00099464e+01\n",
      "  -1.15067740e+00  3.78695957e+00]\n",
      " [-8.13559523e+01 -5.81208327e+01  5.96350802e+00 -2.66372333e+01\n",
      "  -8.30319717e+00  1.10825613e+01 -2.76455510e+01 -2.29857298e-01\n",
      "   4.35833856e-01 -6.34740721e+00]\n",
      " [-8.03287693e+01 -6.15073325e+01  9.74505186e+00 -3.45142455e+01\n",
      "   2.44944049e+00 -7.03342614e+00 -1.50962366e+01 -4.80332752e+00\n",
      "  -5.59949720e-01  7.13517022e+00]\n",
      " [-6.22872260e+01 -4.38505903e+01  1.26629496e+01 -2.76839525e+01\n",
      "  -1.57442736e+01 -3.96582669e+00  4.02826991e+00 -9.85745544e-01\n",
      "   9.96872453e-01 -1.17743302e+00]\n",
      " [-7.98140311e+01 -6.07965617e+01  8.59601843e+00 -3.44026206e+01\n",
      "   2.54517221e+00 -1.10256829e+01 -1.68535155e+01 -2.37553071e-01\n",
      "  -3.24066589e-01  6.05808583e+00]\n",
      " [-6.34947366e+01 -5.40073363e+01  1.24595871e+01 -3.63356017e+01\n",
      "  -3.45899190e+00 -3.36947882e+00 -1.60312188e+01 -1.26803098e+01\n",
      "  -2.57787720e+00  3.75887982e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Project report.aux\"\\n5 0.7254756251686398\\n10 0.8747829463301018\\n15 0.93963397065257\\n20 0.9707914244773223\\n25 0.9860049325538303\\n30 0.9927169174060696\\n35 0.9964934674252495\\n40 0.9986133518375307\\n45 0.999622615506004\\n50 0.9999261757883421\\n55 1.0000000000000002\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test filed to find the reaonable number of components to reach about 70% of the variance. Reduce the dimension of the data and training time.\n",
    "'''\"Project report.aux\"'\n",
    "# Do not run this in training. It is just for testing purpose.\n",
    "\n",
    "# Read the data from the CSV file\n",
    "directory = r\"G:\\\\Songs\\\\AAA\\\\start\\\\Hello.csv\"\n",
    "filepaths = os.path.join(directory)\n",
    "df = pd.read_csv(filepaths).T\n",
    "\n",
    "# Print the shape of the DataFrame\n",
    "print(df.shape)\n",
    "\n",
    "#Check the cumulative variance for each number of components\n",
    "for k in range(5, 60, 5):\n",
    "    pca = PCA(n_components=k)\n",
    "    reduced_data = pca.fit_transform(df)\n",
    "    cumulative_var = np.sum(pca.explained_variance_ratio_[:k + 1])\n",
    "    print(k, cumulative_var)\n",
    "#cumulative_var = np.sum(pca.explained_variance_ratio_[:k + 1])\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "reduced_data = pca.fit_transform(df)\n",
    "# Define the output file path\n",
    "output_file_path = os.path.join(r\"G:\\\\Songs\\\\AAA\\\\\", \"reduced_data.csv\")\n",
    "\n",
    "# Create a DataFrame from the reduced data\n",
    "reduced_df = pd.DataFrame(reduced_data)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "reduced_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(reduced_data.shape)\n",
    "print(reduced_data)\n",
    "'''\n",
    "'''\"Project report.aux\"\n",
    "5 0.7254756251686398\n",
    "10 0.8747829463301018\n",
    "15 0.93963397065257\n",
    "20 0.9707914244773223\n",
    "25 0.9860049325538303\n",
    "30 0.9927169174060696\n",
    "35 0.9964934674252495\n",
    "40 0.9986133518375307\n",
    "45 0.999622615506004\n",
    "50 0.9999261757883421\n",
    "55 1.0000000000000002\n",
    "'''\n",
    "# 10 components are good enough for me now. Apply 10 to the rest of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I will use the same training strategy three times, I would rather just define the similar procedures as funtions for clarity:\n",
    "\n",
    "Now I will define the PCA, SVM and NN functions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# folder is the folder name. For example, start, mid, end\n",
    "# PCA_10 is the function to reduce the dimension of the data to 10.\n",
    "def PCA_10 (folder):\n",
    "    # Define the directory path\n",
    "    directory = r\"G:\\Songs\"\n",
    "\n",
    "    # Initialize an empty dictionary to store the reduced data\n",
    "    reduced_data = {}\n",
    "    reduced_testing_data = {}\n",
    "    # check the start folder only in this case\n",
    "\n",
    "    for singer in os.listdir(directory):\n",
    "        # Skip unlabelled singers\n",
    "        if singer == \"Unlabeled\":\n",
    "            print(\"Prepare the testing data\")\n",
    "            \n",
    "            for filename in os.listdir(os.path.join(directory, singer, folder)):\n",
    "                #print(\"Processing file\", filename)\n",
    "                if filename.endswith(\".csv\"):\n",
    "                    \n",
    "                    # Construct the file path\n",
    "                    filepath = os.path.join(os.path.join(directory, singer, folder, filename))\n",
    "                    \n",
    "                    # Read the .csv file into a dataframe\n",
    "                    df = pd.read_csv(filepath)\n",
    "                    \n",
    "                    # Apply PCA to reduce the dimension of the data\n",
    "                    pca = PCA(n_components=10)  \n",
    "                    reduce = pca.fit_transform(df)\n",
    "                    \n",
    "                    # For testing data, the singer label is the filename. So after prediction, it need to compare with the filename. \n",
    "                    reduced_testing_data[filename] = [reduce]\n",
    "        else:\n",
    "            print(\"Processing singer\", singer)\n",
    "            # Singer directories\n",
    "            for filename in os.listdir(os.path.join(directory, singer, folder)):\n",
    "                #print(\"Processing file\", filename)\n",
    "                if filename.endswith(\".csv\"):\n",
    "                    \n",
    "                    # Construct the file path\n",
    "                    filepath = os.path.join(os.path.join(directory, singer, folder, filename))\n",
    "                    \n",
    "                    # Read the .csv file into a dataframe\n",
    "                    df = pd.read_csv(filepath)\n",
    "                    \n",
    "                    # Apply PCA to reduce the dimension of the data\n",
    "                    pca = PCA(n_components=10)  \n",
    "                    reduce = pca.fit_transform(df)\n",
    "                    \n",
    "                    # Get the singer label from the folder name\n",
    "                    singer_label = singer\n",
    "                    \n",
    "                    # Check if the singer label already exists in the dictionary\n",
    "                    if singer_label in reduced_data:\n",
    "                        # Append the dataframe to the existing list\n",
    "                        reduced_data[singer_label].append(reduce)\n",
    "                    else:\n",
    "                        # Create a new list with the dataframe\n",
    "                        reduced_data[singer_label] = [reduce]\n",
    "\n",
    "    # Now all the data here are ready to train.\n",
    "\n",
    "    # Prepare the data for training\n",
    "    X = []\n",
    "    y = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "\n",
    "    # Iterate over the reduced_data dictionary\n",
    "    for label, data in reduced_data.items():\n",
    "        # Append the reduced data to X\n",
    "        X.extend(data)\n",
    "        # Append the label to y\n",
    "        y.extend([label] * len(data))\n",
    "\n",
    "    # Also get the testing data\n",
    "    for label, data in reduced_testing_data.items():\n",
    "\n",
    "        X_test.extend(data)\n",
    "        \n",
    "        y_test.extend([label] * len(data))\n",
    "        \n",
    "    # At this point, X = (207,124,10) Need to reshape it to (207,1240)\n",
    "    # Reshape X to (207, 1240)\n",
    "    X = np.array(X).reshape(len(X), -1)\n",
    "    X_test = np.array(X_test).reshape(len(X_test), -1)\n",
    "    # print(\"Dimension of y:\", np.array(y).shape)\n",
    "    # print(\"Dimension of x:\", np.array(X).shape)\n",
    "    # print(\"Dimension of y_test:\", np.array(y_test).shape)\n",
    "    # print(\"Dimension of x_test:\", np.array(X_test).shape)\n",
    "    \n",
    "    # Return the data that is reduced by PCA\n",
    "    return X, y, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Now train the model with SVM, figure out the best parameter and the best prediction accuracy\n",
    "def SVM_Search(X, y, X_test, y_test):\n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 5, 10, 100],\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        #'gamma': [0.1, 1, 10, 'auto']\n",
    "    }\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    svm = SVC()\n",
    "\n",
    "    # Perform grid search to find the best parameters\n",
    "    print(\"Performing grid search...\")\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "    print(\"Fitting the grid search...\")\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "\n",
    "    clear_output()\n",
    "    # Print the best parameters\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "    # Train the SVM classifier with the best parameters\n",
    "    svm = grid_search.best_estimator_\n",
    "    \n",
    "    # Predict the labels for the test data\n",
    "    y_pred = svm.predict(X_test)\n",
    "\n",
    "    # Check if y_pred is in y_test\n",
    "    contains_pred = []\n",
    "\n",
    "    # Print the pairs and check if y_test contains y_pred\n",
    "    for pred, test in zip(y_pred, y_test):\n",
    "        print(\"y_pred:\", pred)\n",
    "        print(\"y_test:\", test)\n",
    "        contains_pred.append(pred in test)\n",
    "        \n",
    "    # Create an array of all True values with the same size as contains_pred\n",
    "    all_true = np.full_like(contains_pred, True)\n",
    "    # Calculate the accuracy of the model\n",
    "    accuracy = accuracy_score(all_true, contains_pred)\n",
    "\n",
    "    # Print the accuracy\n",
    "    print(\"Accuracy on test set:\", accuracy)\n",
    "    \n",
    "    return accuracy, grid_search.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems like tensorflow does not work with GridSearchCV. Need to guess the best parameters and do it manually.\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Now train the model with NN, figure out the best parameter and the best prediction accuracy\n",
    "def NN_Search(X,y,X_test,y_test):\n",
    "    # Define the parameter grid to search manually\n",
    "    param_grid = {\n",
    "        'units': [16, 32, 64, 128, 256],\n",
    "        'epochs': [5, 10, 20, 30],\n",
    "        'batch_size': [16, 32, 64]\n",
    "    }\n",
    "\n",
    "    # Use these to collect the best parameters\n",
    "    best_accuracy = 0\n",
    "    best_params_ = None\n",
    "    self_accuracy = 0\n",
    "    best_model = None\n",
    "\n",
    "    # For some reason, it seems like tensorflow does not like string, need to convert y to float.\n",
    "    dictionary = {}\n",
    "    number = 0\n",
    "    for singer in y:\n",
    "        if singer not in dictionary:\n",
    "            dictionary[singer] = number\n",
    "            number = number + 1\n",
    "        \n",
    "    y_tensor = [dictionary[singer] for singer in y]\n",
    "\n",
    "    # Do the same thing for y_test, but need to check with the file name instead\n",
    "    y_test_tensor = []\n",
    "\n",
    "    for filename in y_test:\n",
    "        for singer in dictionary:\n",
    "            if singer in filename:\n",
    "                y_test_tensor.append(dictionary[singer])\n",
    "                break\n",
    "\n",
    "    # Convert X, y, X_test, and y_test to tensors\n",
    "    X_tensor = tf.convert_to_tensor(X)\n",
    "    y_tensor = tf.convert_to_tensor(y_tensor)\n",
    "    X_test_tensor = tf.convert_to_tensor(X_test)\n",
    "    y_test_tensor = tf.convert_to_tensor(y_test_tensor)\n",
    "\n",
    "\n",
    "    for units in param_grid['units']:\n",
    "        for epochs in param_grid['epochs']:\n",
    "            for batch_size in param_grid['batch_size']:\n",
    "                # Create a model\n",
    "                model = tf.keras.models.Sequential([\n",
    "                    tf.keras.layers.Flatten(input_shape=(X.shape[1],)),\n",
    "                    tf.keras.layers.Dense(units, activation='relu'),\n",
    "                    # Seems like the line below could limit the output to be 16, which is the number of singers.\n",
    "                    tf.keras.layers.Dense(16, activation=tf.keras.activations.softmax, name='output')\n",
    "                    # Not sure how exactly it works, but it works.\n",
    "                ])\n",
    "                model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    metrics=['accuracy'])\n",
    "                \n",
    "                # Train the model\n",
    "                model.fit(X, y_tensor, epochs=epochs, batch_size=batch_size)\n",
    "                \n",
    "                # Evaluate the model on the test set\n",
    "                result = model.evaluate(X, y_tensor)\n",
    "                print(result)\n",
    "                \n",
    "                if (result[1] > self_accuracy):\n",
    "                    self_accuracy = result[1]\n",
    "                \n",
    "                result = model.evaluate(X_test, y_test_tensor)\n",
    "                print(result)\n",
    "                \n",
    "                if (result[1] > best_accuracy):\n",
    "                    best_model = model\n",
    "                    best_accuracy = result[1]\n",
    "                    best_params_ = (units, epochs, batch_size)\n",
    "                    \n",
    "                    \n",
    "    # Just show the results here, do not show the Tensorflow training output             \n",
    "    clear_output()\n",
    "\n",
    "    print(\"Best parameters:\", best_params_)\n",
    "    print(\"Best accuracy:\", best_accuracy)\n",
    "\n",
    "    model = best_model\n",
    "\n",
    "    # predict the labels for the test data\n",
    "    y_pred_tensor = model.predict(X_test_tensor)\n",
    "    y_pred_tensor = tf.argmax(y_pred_tensor, axis=1).numpy()\n",
    "\n",
    "    y_pred = []\n",
    "\n",
    "    # Find the corresponding key in the dictionary and replace the value\n",
    "    for i in range(len(y_pred_tensor)):\n",
    "        found_match = False\n",
    "        for key, value in dictionary.items():\n",
    "            if value == y_pred_tensor[i]:\n",
    "                y_pred.append(key)\n",
    "                found_match = True\n",
    "                break\n",
    "        if not found_match:\n",
    "            # This is here because before the NN model would predict sth out of the dictionary\n",
    "            # Now it should not happen anymore\n",
    "            y_pred.append(\"unknown\")\n",
    "        \n",
    "\n",
    "    # Print the predictions and the actual labels\n",
    "    for pred_tensor, test_tensor in zip(y_pred, y_test):\n",
    "        print(\"y_pred_tensor:\", pred_tensor)\n",
    "        print(\"y_test_tensor:\", test_tensor)\n",
    "        \n",
    "    # Print the accuracy\n",
    "    #print(\"Best accuracy on self: \", self_accuracy)\n",
    "    \n",
    "    return best_accuracy, best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply PCA to the 'start' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing singer AAA\n",
      "Prepare the testing data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing singer 五月天\n",
      "Processing singer 吴青峰\n",
      "Processing singer 周杰伦\n",
      "Processing singer 声音玩具\n",
      "Processing singer 康士坦的变化球\n",
      "Processing singer 张学友\n",
      "Processing singer 方大同\n",
      "Processing singer 杨乃文\n",
      "Processing singer 林俊杰\n",
      "Processing singer 林忆莲\n",
      "Processing singer 王力宏\n",
      "Processing singer 王菲\n",
      "Processing singer 重塑雕像的权利\n",
      "Processing singer 陈奕迅\n",
      "Processing singer 陶喆\n"
     ]
    }
   ],
   "source": [
    "X, y, X_test, y_test = PCA_10('start')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply SVM on the 'start' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'kernel': 'rbf'}\n",
      "y_pred: 周杰伦\n",
      "y_test: 周杰伦 - 听见下雨的声音.mp3.csv\n",
      "y_pred: 王菲\n",
      "y_test: 周杰伦 - 美人鱼.mp3.csv\n",
      "y_pred: 周杰伦\n",
      "y_test: 周杰伦、张惠妹 - 不该 (with aMEI).mp3.csv\n",
      "y_pred: 张学友\n",
      "y_test: 方大同 - Love Song.mp3.csv\n",
      "y_pred: 方大同\n",
      "y_test: 方大同 - 好不容易.mp3.csv\n",
      "y_pred: 张学友\n",
      "y_test: 方大同 - 红豆.mp3.csv\n",
      "y_pred: 方大同\n",
      "y_test: 林俊杰 - 她说.mp3.csv\n",
      "y_pred: 方大同\n",
      "y_test: 林俊杰 - 学不会.mp3.csv\n",
      "y_pred: 周杰伦\n",
      "y_test: 王菲 - 当时的月亮.mp3.csv\n",
      "y_pred: 王菲\n",
      "y_test: 陶喆 - 黑色柳丁.mp3.csv\n",
      "Accuracy on test set: 0.3\n"
     ]
    }
   ],
   "source": [
    "start_SVM_acc, start_SVM_param = SVM_Search(X, y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply NN on the 'start' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: (32, 30, 32)\n",
      "Best accuracy: 0.5\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "y_pred_tensor: 周杰伦\n",
      "y_test_tensor: 周杰伦 - 听见下雨的声音.mp3.csv\n",
      "y_pred_tensor: 周杰伦\n",
      "y_test_tensor: 周杰伦 - 美人鱼.mp3.csv\n",
      "y_pred_tensor: 周杰伦\n",
      "y_test_tensor: 周杰伦、张惠妹 - 不该 (with aMEI).mp3.csv\n",
      "y_pred_tensor: 五月天\n",
      "y_test_tensor: 方大同 - Love Song.mp3.csv\n",
      "y_pred_tensor: 周杰伦\n",
      "y_test_tensor: 方大同 - 好不容易.mp3.csv\n",
      "y_pred_tensor: 方大同\n",
      "y_test_tensor: 方大同 - 红豆.mp3.csv\n",
      "y_pred_tensor: 张学友\n",
      "y_test_tensor: 林俊杰 - 她说.mp3.csv\n",
      "y_pred_tensor: 陶喆\n",
      "y_test_tensor: 林俊杰 - 学不会.mp3.csv\n",
      "y_pred_tensor: 方大同\n",
      "y_test_tensor: 王菲 - 当时的月亮.mp3.csv\n",
      "y_pred_tensor: 陶喆\n",
      "y_test_tensor: 陶喆 - 黑色柳丁.mp3.csv\n"
     ]
    }
   ],
   "source": [
    "start_NN_acc, start_NN_param = NN_Search(X, y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply PCA to the 'mid' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing singer AAA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare the testing data\n",
      "Processing singer 五月天\n",
      "Processing singer 吴青峰\n",
      "Processing singer 周杰伦\n",
      "Processing singer 声音玩具\n",
      "Processing singer 康士坦的变化球\n",
      "Processing singer 张学友\n",
      "Processing singer 方大同\n",
      "Processing singer 杨乃文\n",
      "Processing singer 林俊杰\n",
      "Processing singer 林忆莲\n",
      "Processing singer 王力宏\n",
      "Processing singer 王菲\n",
      "Processing singer 重塑雕像的权利\n",
      "Processing singer 陈奕迅\n",
      "Processing singer 陶喆\n"
     ]
    }
   ],
   "source": [
    "X, y, X_test, y_test = PCA_10('mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply SVM on the 'mid' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'kernel': 'rbf'}\n",
      "y_pred: 周杰伦\n",
      "y_test: 周杰伦 - 听见下雨的声音.mp3.csv\n",
      "y_pred: 王菲\n",
      "y_test: 周杰伦 - 美人鱼.mp3.csv\n",
      "y_pred: 周杰伦\n",
      "y_test: 周杰伦、张惠妹 - 不该 (with aMEI).mp3.csv\n",
      "y_pred: 张学友\n",
      "y_test: 方大同 - Love Song.mp3.csv\n",
      "y_pred: 方大同\n",
      "y_test: 方大同 - 好不容易.mp3.csv\n",
      "y_pred: 张学友\n",
      "y_test: 方大同 - 红豆.mp3.csv\n",
      "y_pred: 方大同\n",
      "y_test: 林俊杰 - 她说.mp3.csv\n",
      "y_pred: 方大同\n",
      "y_test: 林俊杰 - 学不会.mp3.csv\n",
      "y_pred: 周杰伦\n",
      "y_test: 王菲 - 当时的月亮.mp3.csv\n",
      "y_pred: 王菲\n",
      "y_test: 陶喆 - 黑色柳丁.mp3.csv\n",
      "Accuracy on test set: 0.3\n"
     ]
    }
   ],
   "source": [
    "mid_SVM_acc, mid_SVM_param = SVM_Search(X, y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply NN on the 'mid' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: (256, 30, 32)\n",
      "Best accuracy: 0.4000000059604645\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "y_pred_tensor: 周杰伦\n",
      "y_test_tensor: 周杰伦 - 听见下雨的声音.mp3.csv\n",
      "y_pred_tensor: 方大同\n",
      "y_test_tensor: 周杰伦 - 美人鱼.mp3.csv\n",
      "y_pred_tensor: 周杰伦\n",
      "y_test_tensor: 周杰伦、张惠妹 - 不该 (with aMEI).mp3.csv\n",
      "y_pred_tensor: 王菲\n",
      "y_test_tensor: 方大同 - Love Song.mp3.csv\n",
      "y_pred_tensor: 王力宏\n",
      "y_test_tensor: 方大同 - 好不容易.mp3.csv\n",
      "y_pred_tensor: 方大同\n",
      "y_test_tensor: 方大同 - 红豆.mp3.csv\n",
      "y_pred_tensor: 林俊杰\n",
      "y_test_tensor: 林俊杰 - 她说.mp3.csv\n",
      "y_pred_tensor: 王力宏\n",
      "y_test_tensor: 林俊杰 - 学不会.mp3.csv\n",
      "y_pred_tensor: 陶喆\n",
      "y_test_tensor: 王菲 - 当时的月亮.mp3.csv\n",
      "y_pred_tensor: 周杰伦\n",
      "y_test_tensor: 陶喆 - 黑色柳丁.mp3.csv\n"
     ]
    }
   ],
   "source": [
    "mid_NN_acc, mid_NN_param = NN_Search(X, y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply PCA to the 'end' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing singer AAA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare the testing data\n",
      "Processing singer 五月天\n",
      "Processing singer 吴青峰\n",
      "Processing singer 周杰伦\n",
      "Processing singer 声音玩具\n",
      "Processing singer 康士坦的变化球\n",
      "Processing singer 张学友\n",
      "Processing singer 方大同\n",
      "Processing singer 杨乃文\n",
      "Processing singer 林俊杰\n",
      "Processing singer 林忆莲\n",
      "Processing singer 王力宏\n",
      "Processing singer 王菲\n",
      "Processing singer 重塑雕像的权利\n",
      "Processing singer 陈奕迅\n",
      "Processing singer 陶喆\n"
     ]
    }
   ],
   "source": [
    "X, y, X_test, y_test = PCA_10('end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply SVM on the 'end' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'kernel': 'rbf'}\n",
      "y_pred: 周杰伦\n",
      "y_test: 周杰伦 - 听见下雨的声音.mp3.csv\n",
      "y_pred: 王菲\n",
      "y_test: 周杰伦 - 美人鱼.mp3.csv\n",
      "y_pred: 周杰伦\n",
      "y_test: 周杰伦、张惠妹 - 不该 (with aMEI).mp3.csv\n",
      "y_pred: 张学友\n",
      "y_test: 方大同 - Love Song.mp3.csv\n",
      "y_pred: 方大同\n",
      "y_test: 方大同 - 好不容易.mp3.csv\n",
      "y_pred: 张学友\n",
      "y_test: 方大同 - 红豆.mp3.csv\n",
      "y_pred: 方大同\n",
      "y_test: 林俊杰 - 她说.mp3.csv\n",
      "y_pred: 方大同\n",
      "y_test: 林俊杰 - 学不会.mp3.csv\n",
      "y_pred: 周杰伦\n",
      "y_test: 王菲 - 当时的月亮.mp3.csv\n",
      "y_pred: 王菲\n",
      "y_test: 陶喆 - 黑色柳丁.mp3.csv\n",
      "Accuracy on test set: 0.3\n"
     ]
    }
   ],
   "source": [
    "end_SVM_acc, end_SVM_param = SVM_Search(X, y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply NN on the 'end' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: (128, 20, 64)\n",
      "Best accuracy: 0.6000000238418579\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "y_pred_tensor: 周杰伦\n",
      "y_test_tensor: 周杰伦 - 听见下雨的声音.mp3.csv\n",
      "y_pred_tensor: 王力宏\n",
      "y_test_tensor: 周杰伦 - 美人鱼.mp3.csv\n",
      "y_pred_tensor: 周杰伦\n",
      "y_test_tensor: 周杰伦、张惠妹 - 不该 (with aMEI).mp3.csv\n",
      "y_pred_tensor: 方大同\n",
      "y_test_tensor: 方大同 - Love Song.mp3.csv\n",
      "y_pred_tensor: 周杰伦\n",
      "y_test_tensor: 方大同 - 好不容易.mp3.csv\n",
      "y_pred_tensor: 陈奕迅\n",
      "y_test_tensor: 方大同 - 红豆.mp3.csv\n",
      "y_pred_tensor: 林俊杰\n",
      "y_test_tensor: 林俊杰 - 她说.mp3.csv\n",
      "y_pred_tensor: 张学友\n",
      "y_test_tensor: 林俊杰 - 学不会.mp3.csv\n",
      "y_pred_tensor: 王菲\n",
      "y_test_tensor: 王菲 - 当时的月亮.mp3.csv\n",
      "y_pred_tensor: 陶喆\n",
      "y_test_tensor: 陶喆 - 黑色柳丁.mp3.csv\n"
     ]
    }
   ],
   "source": [
    "end_NN_acc, end_NN_param = NN_Search(X, y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is too similar and it is not what I would expect it to be. I am expecting a higher accuracy. So now, I try to train with all three snippets and then add cross validation if possible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Get the data from all three folders\n",
    "def PCA_10_all():\n",
    "    # Define the directory path\n",
    "    directory = r\"G:\\Songs\"\n",
    "\n",
    "    # Initialize an empty dictionary to store the reduced data\n",
    "    reduced_data = {}\n",
    "    reduced_testing_data = {}\n",
    "    # check the start folder only in this case\n",
    "\n",
    "    for singer in os.listdir(directory):\n",
    "        # Skip unlabelled singers\n",
    "        if singer == \"Unlabeled\":\n",
    "            print(\"Prepare the testing data\")\n",
    "            \n",
    "            for folder in os.listdir(os.path.join(directory, singer)):\n",
    "                # make sure it is a folder\n",
    "                folder_path = os.path.join(directory, singer, folder)\n",
    "                if os.path.isdir(folder_path):\n",
    "                    #print(\"Processing folder\", folder)\n",
    "                    for filename in os.listdir(folder_path):\n",
    "                        #print(\"Processing file\", filename)\n",
    "                        if filename.endswith(\".csv\"):\n",
    "                            # Construct the file path\n",
    "                            filepath = os.path.join(folder_path, filename)\n",
    "                            \n",
    "                            # Read the .csv file into a dataframe\n",
    "                            df = pd.read_csv(filepath)\n",
    "                            \n",
    "                            # Apply PCA to reduce the dimension of the data\n",
    "                            pca = PCA(n_components=10)  \n",
    "                            reduce = pca.fit_transform(df)\n",
    "                            \n",
    "                            # For testing data, the singer label is the filename. So after prediction, it needs to compare with the filename. \n",
    "                            if filename in reduced_testing_data:\n",
    "                                # If the label exists in the dictionary, concatenate the arrays\n",
    "                                existing_array = reduced_testing_data[filename]\n",
    "                                combined_array = np.concatenate([existing_array, reduce], axis=0)\n",
    "                                reduced_testing_data[filename] = combined_array\n",
    "                                #print(combined_array.shape)\n",
    "                            else:\n",
    "                                # Create a new list with the dataframe\n",
    "                                reduced_testing_data[filename] = reduce\n",
    "        else:\n",
    "            print(\"Processing singer\", singer)\n",
    "            # Singer directories\n",
    "            \n",
    "            # Initialize an empty dictionary to store the reduced data\n",
    "            song_look_up = {}\n",
    "            for folder in os.listdir(os.path.join(directory, singer)):\n",
    "                \n",
    "                folder_path = os.path.join(directory, singer, folder)\n",
    "                if os.path.isdir(folder_path):\n",
    "                    #print(\"Processing folder\", folder)\n",
    "                    for filename in os.listdir(folder_path):\n",
    "                        #print(\"Processing file\", filename)\n",
    "                        if filename.endswith(\".csv\"):\n",
    "                            # Construct the file path\n",
    "                            filepath = os.path.join(folder_path, filename)\n",
    "                            \n",
    "                            # Read the .csv file into a dataframe\n",
    "                            df = pd.read_csv(filepath)\n",
    "                            \n",
    "                            # Apply PCA to reduce the dimension of the data\n",
    "                            pca = PCA(n_components=10)  \n",
    "                            reduce = pca.fit_transform(df)\n",
    "                            \n",
    "                            if filename in song_look_up:\n",
    "                                # If the label exists in the dictionary, concatenate the arrays\n",
    "                                existing_array = song_look_up[filename]\n",
    "                                combined_array = np.concatenate([existing_array, reduce], axis=0)\n",
    "                                song_look_up[filename] = combined_array\n",
    "                                #print(combined_array.shape)\n",
    "                            else:\n",
    "                                # Create a new list with the dataframe\n",
    "                                song_look_up[filename] = reduce\n",
    "                \n",
    "            # Get the singer label from the folder name\n",
    "            singer_label = singer\n",
    "            \n",
    "            # add all the data from the song_look_up dictionary to the reduced_data dictionary\n",
    "            reduced_data[singer_label] = []\n",
    "            \n",
    "            # Iterate over the song_look_up dictionary\n",
    "            for label, data in song_look_up.items():\n",
    "                # Append the reduced data to X\n",
    "                reduced_data[singer_label].append(data)\n",
    "                #print(\"Dimension of data:\", np.array(data).shape)\n",
    "\n",
    "    # Now all the data here are ready to train.\n",
    "\n",
    "    # Prepare the data for training\n",
    "    X = []\n",
    "    y = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    # Iterate over the reduced_data dictionary\n",
    "    for label, data in reduced_data.items():\n",
    "        # Append the reduced data to X\n",
    "        X.extend(data)\n",
    "        # Append the label to y\n",
    "        y.extend([label] * len(data))\n",
    "\n",
    "\n",
    "    print(reduced_testing_data.keys())\n",
    "    print(reduced_testing_data.values())\n",
    "    # Also get the testing data\n",
    "    for label, data in reduced_testing_data.items():\n",
    "        X_test.append(data)\n",
    "        y_test.append(label)\n",
    "        \n",
    "    # At this point, X = (207,124,10) Need to reshape it to (207,1240)\n",
    "    # Reshape X to (207, 1240)\n",
    "    X = np.array(X).reshape(len(X), -1)\n",
    "    X_test = np.array(X_test).reshape(len(X_test), -1)\n",
    "    # print(\"Dimension of y:\", np.array(y).shape)\n",
    "    # print(\"Dimension of x:\", np.array(X).shape)\n",
    "    # print(\"Dimension of y_test:\", np.array(y_test).shape)\n",
    "    # print(\"Dimension of x_test:\", np.array(X_test).shape)\n",
    "    \n",
    "    # Return the data that is reduced by PCA\n",
    "    return X, y, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing singer AAA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare the testing data\n",
      "Processing singer 五月天\n",
      "Processing singer 吴青峰\n",
      "Processing singer 周杰伦\n",
      "Processing singer 声音玩具\n",
      "Processing singer 康士坦的变化球\n",
      "Processing singer 张学友\n",
      "Processing singer 方大同\n",
      "Processing singer 杨乃文\n",
      "Processing singer 林俊杰\n",
      "Processing singer 林忆莲\n",
      "Processing singer 王力宏\n",
      "Processing singer 王菲\n",
      "Processing singer 重塑雕像的权利\n",
      "Processing singer 陈奕迅\n",
      "Processing singer 陶喆\n",
      "dict_keys(['周杰伦 - 听见下雨的声音.mp3.csv', '周杰伦 - 美人鱼.mp3.csv', '周杰伦、张惠妹 - 不该 (with aMEI).mp3.csv', '方大同 - Love Song.mp3.csv', '方大同 - 好不容易.mp3.csv', '方大同 - 红豆.mp3.csv', '林俊杰 - 她说.mp3.csv', '林俊杰 - 学不会.mp3.csv', '王菲 - 当时的月亮.mp3.csv', '陶喆 - 黑色柳丁.mp3.csv'])\n",
      "dict_values([array([[-51.87849508, -60.16807359,  -5.01478259, ...,  -2.57256638,\n",
      "          1.27569282,   6.79853216],\n",
      "       [-43.95747796, -52.22677898, -12.2041698 , ...,  -3.78801746,\n",
      "         -3.82582278, -15.30169152],\n",
      "       [-40.45568227, -57.61629335, -16.29715325, ...,  -5.73669795,\n",
      "        -16.46471565, -63.41656665],\n",
      "       ...,\n",
      "       [ 21.73248212, 165.33404478, -56.65772229, ...,  61.93737118,\n",
      "         -9.60115453,  -3.8111466 ],\n",
      "       [ 38.5480804 , 210.85514447, -44.63315214, ...,  10.65784437,\n",
      "        -19.97419687,   3.23218993],\n",
      "       [  0.2606458 , 195.85563965, -81.45149146, ..., 109.53797356,\n",
      "          3.43175323, -40.25414777]]), array([[-93.11413629, -29.8154983 ,  -9.399929  , ..., -34.48988592,\n",
      "          4.65473678,   8.00602516],\n",
      "       [-99.68480658, -27.99534625,   3.71817536, ..., -25.88437522,\n",
      "          7.15906044,  -3.42850157],\n",
      "       [140.0085631 , 191.37116562,  42.91764053, ...,   4.47406263,\n",
      "        -26.80255485, -45.67701603],\n",
      "       ...,\n",
      "       [-86.59899304, -19.35838836,   9.07105794, ..., -15.1037817 ,\n",
      "          1.0317888 ,   1.23592657],\n",
      "       [ 56.50475854, 148.56294302, -10.20536397, ...,   1.49598827,\n",
      "         22.40007727, -16.06872446],\n",
      "       [137.27815053, -22.99177006,   4.56065782, ...,  15.9197011 ,\n",
      "         12.88311821,   8.41935729]]), array([[-4.57007511e+01,  4.62163899e+01,  1.11232770e+02, ...,\n",
      "         3.63077567e+01,  4.06294841e+01,  5.85517981e+01],\n",
      "       [-5.83448844e+01,  7.29270466e+01,  2.62704431e+02, ...,\n",
      "        -3.06880248e+01,  1.39421492e+01, -4.15911358e+00],\n",
      "       [-7.70030003e+01,  5.89547274e+01,  2.35053775e+02, ...,\n",
      "        -2.23374945e+01,  1.26049785e+01,  7.79413644e-02],\n",
      "       ...,\n",
      "       [ 1.62892442e+02,  4.32678463e+01,  3.03296612e+02, ...,\n",
      "        -2.12701157e+01,  1.25325524e+01,  4.94292393e+00],\n",
      "       [ 1.64848410e+02,  5.79146331e+01,  2.65493993e+02, ...,\n",
      "        -1.49122561e+01, -1.27291747e+01,  1.96391660e+00],\n",
      "       [ 6.59628493e+01,  2.85154363e+01,  3.13868153e+02, ...,\n",
      "        -4.29378938e-01, -1.59687097e+01, -9.64723705e+00]]), array([[ 1.05787201e+00,  3.23462864e+01,  7.65203985e+00, ...,\n",
      "         1.79503407e+01,  4.13073054e-01, -1.20229060e+01],\n",
      "       [-2.31243764e+00,  3.26404544e+01,  5.75658096e+00, ...,\n",
      "         1.10711750e+01, -1.40988357e+00, -1.53229208e+01],\n",
      "       [-4.06825799e+00,  4.71178324e+01,  8.10514645e-02, ...,\n",
      "         3.27819437e+00, -3.74634276e+00, -1.54770532e+01],\n",
      "       ...,\n",
      "       [-2.87591587e+01, -1.50304206e+01,  1.13643215e+01, ...,\n",
      "        -2.72164482e+00,  6.96977391e-01, -6.91253265e-01],\n",
      "       [ 7.34431282e+01, -1.90096418e+00, -4.16389560e+01, ...,\n",
      "         2.10969943e+01, -2.66014675e+01, -3.87814019e+00],\n",
      "       [ 2.60243290e+02, -1.31105318e+01,  4.37594804e+01, ...,\n",
      "        -1.09398754e+01, -5.77190745e+00,  9.16505400e+00]]), array([[  30.02445153, -109.72283831,   -2.60697404, ...,   25.89702485,\n",
      "         -16.55288892,   15.0769411 ],\n",
      "       [  59.50080482,  -99.06332963,    7.04281629, ...,   27.93093405,\n",
      "         -10.84857529,   27.72644655],\n",
      "       [  49.57402247, -100.48875872,   -8.43299391, ...,   19.56690287,\n",
      "         -14.43434701,   20.76431636],\n",
      "       ...,\n",
      "       [  63.94594088,  -72.87811854,  -52.91223338, ...,  -35.85078309,\n",
      "          -3.33423555,   -9.89307286],\n",
      "       [  59.22064256,  -60.01354735,  -47.94865122, ...,   -1.2113052 ,\n",
      "         -23.75630191,   -9.98733539],\n",
      "       [  48.20807891,  -75.71799049,  -58.52551462, ...,    8.73359762,\n",
      "          -9.47372027,   -7.86784786]]), array([[-21.50851897, -24.85951193,  -1.90301699, ...,  -7.5719451 ,\n",
      "          7.21869792,  47.70897582],\n",
      "       [-27.44831358, -23.2190154 ,  -7.78199132, ...,  -4.19681406,\n",
      "          4.69077114,  42.52374039],\n",
      "       [-28.92163696, -21.49563579, -10.41501309, ...,  -3.650007  ,\n",
      "          3.33635906,  36.25782218],\n",
      "       ...,\n",
      "       [ 11.7230381 , -13.69168153, -30.30684501, ...,  28.24083865,\n",
      "         47.01577741, -10.05441909],\n",
      "       [  5.90625683, -24.93580948, -37.33687755, ...,  28.94992194,\n",
      "         80.49772973, -20.83693025],\n",
      "       [-10.15661499, -32.6570201 , -31.13538955, ...,  23.67809563,\n",
      "         62.18317661, -16.32330239]]), array([[ -48.59272996,  -70.40474201,  -94.24047415, ...,   13.99378333,\n",
      "          17.35207607,  -22.72333607],\n",
      "       [ -43.4800554 ,  -60.08270983,  -90.37821075, ...,   17.43780676,\n",
      "          35.82016475,    0.47179983],\n",
      "       [ -42.19815666,  -17.09767316, -105.28349077, ...,   34.12725895,\n",
      "         105.84507   ,  114.5234881 ],\n",
      "       ...,\n",
      "       [ -13.77272545,    9.66362654,  -31.78990693, ...,  -22.89699127,\n",
      "          35.7815109 ,    2.05592991],\n",
      "       [  -2.14709156,    9.78476415,  -13.42587916, ...,  -18.76834915,\n",
      "          18.98258132,   -1.62630166],\n",
      "       [  23.70339257,    4.39717916,    1.08087919, ...,  -20.38098514,\n",
      "          36.93644907,   -4.23866169]]), array([[-71.66817823, -11.54144413, -41.05708916, ..., -47.83090395,\n",
      "         34.94291505,  -0.62611817],\n",
      "       [-64.92869898,   1.59604804, -43.50893709, ..., -38.61681643,\n",
      "         18.51437105,   5.26534853],\n",
      "       [-67.72558382,  -0.67009615, -42.30450469, ..., -33.89158106,\n",
      "          8.30830255,   5.72861375],\n",
      "       ...,\n",
      "       [-58.26799441, -15.83700981, -33.61333863, ...,  25.48151656,\n",
      "        -18.76080577,  12.94075906],\n",
      "       [ 90.21190489, 107.38849151,   4.76602573, ...,  19.3611518 ,\n",
      "          9.26953854,  13.37606211],\n",
      "       [117.83070539, 166.74411259,  52.27727859, ...,   5.6418959 ,\n",
      "          7.63277141, -14.33000856]]), array([[  25.13851426,   51.37380494, -144.26188736, ...,   -8.22920045,\n",
      "          -8.30301606,  -20.71566295],\n",
      "       [  12.61180101,   46.59708261, -132.88385434, ...,   10.30890421,\n",
      "          -1.9792323 ,  -28.99466222],\n",
      "       [   9.91624356,   39.3703046 , -160.69173007, ...,    8.38786897,\n",
      "         -13.99054915,    2.2214494 ],\n",
      "       ...,\n",
      "       [  97.10625413,  -95.12629752, -105.59014995, ...,   28.31601358,\n",
      "          -4.28911084,   -7.53962393],\n",
      "       [  94.42886621,  -90.31919115, -107.15212408, ...,   13.04699998,\n",
      "          -1.02556281,    9.38073972],\n",
      "       [  84.65038533,  -75.94102835, -102.44191146, ...,   11.21812202,\n",
      "          -0.16279726,    7.04217901]]), array([[-48.13756865, -17.18561821,  32.09110342, ..., -11.45421169,\n",
      "          2.4293989 ,  -1.88153755],\n",
      "       [-51.47446859, -19.23044835,  43.49340957, ..., -21.88605512,\n",
      "          3.7612015 ,  -1.58681555],\n",
      "       [-51.50215726, -19.60888021,  43.70767886, ..., -22.0393579 ,\n",
      "          5.12068548,  -2.2475666 ],\n",
      "       ...,\n",
      "       [ 89.4412885 , -41.55127233,   6.82408912, ..., -52.18016602,\n",
      "          1.03872772, -23.31816099],\n",
      "       [ 82.6113162 , -36.288203  ,   2.16739402, ..., -44.76035014,\n",
      "          5.2976114 , -28.56422425],\n",
      "       [ 76.18692247, -38.64768287,  -0.86424084, ..., -30.50061496,\n",
      "        -18.05526784, -22.11357731]])])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"Dimension of X:\", np.array(X).shape)\\nprint(X)\\nprint(\"Dimension of y:\", np.array(y).shape)\\nprint(y)\\nprint(\"Dimension of X_test:\", np.array(X_test).shape)\\nprint(X_test)\\nprint(\"Dimension of y_test:\", np.array(y_test).shape)\\nprint(y_test)\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, X_test, y_test = PCA_10_all()\n",
    "'''\n",
    "print(\"Dimension of X:\", np.array(X).shape)\n",
    "print(X)\n",
    "print(\"Dimension of y:\", np.array(y).shape)\n",
    "print(y)\n",
    "print(\"Dimension of X_test:\", np.array(X_test).shape)\n",
    "print(X_test)\n",
    "print(\"Dimension of y_test:\", np.array(y_test).shape)\n",
    "print(y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'kernel': 'rbf'}\n",
      "y_pred: 周杰伦\n",
      "y_test: 周杰伦 - 听见下雨的声音.mp3.csv\n",
      "y_pred: 王菲\n",
      "y_test: 周杰伦 - 美人鱼.mp3.csv\n",
      "y_pred: 周杰伦\n",
      "y_test: 周杰伦、张惠妹 - 不该 (with aMEI).mp3.csv\n",
      "y_pred: 张学友\n",
      "y_test: 方大同 - Love Song.mp3.csv\n",
      "y_pred: 方大同\n",
      "y_test: 方大同 - 好不容易.mp3.csv\n",
      "y_pred: 张学友\n",
      "y_test: 方大同 - 红豆.mp3.csv\n",
      "y_pred: 方大同\n",
      "y_test: 林俊杰 - 她说.mp3.csv\n",
      "y_pred: 方大同\n",
      "y_test: 林俊杰 - 学不会.mp3.csv\n",
      "y_pred: 周杰伦\n",
      "y_test: 王菲 - 当时的月亮.mp3.csv\n",
      "y_pred: 王菲\n",
      "y_test: 陶喆 - 黑色柳丁.mp3.csv\n",
      "Accuracy on test set: 0.3\n"
     ]
    }
   ],
   "source": [
    "all_SVM_acc, all_SVM_param = SVM_Search(X, y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: (16, 30, 32)\n",
      "Best accuracy: 0.6000000238418579\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3F6DECA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "y_pred_tensor: 周杰伦\n",
      "y_test_tensor: 周杰伦 - 听见下雨的声音.mp3.csv\n",
      "y_pred_tensor: 林忆莲\n",
      "y_test_tensor: 周杰伦 - 美人鱼.mp3.csv\n",
      "y_pred_tensor: 方大同\n",
      "y_test_tensor: 周杰伦、张惠妹 - 不该 (with aMEI).mp3.csv\n",
      "y_pred_tensor: 方大同\n",
      "y_test_tensor: 方大同 - Love Song.mp3.csv\n",
      "y_pred_tensor: 方大同\n",
      "y_test_tensor: 方大同 - 好不容易.mp3.csv\n",
      "y_pred_tensor: 陈奕迅\n",
      "y_test_tensor: 方大同 - 红豆.mp3.csv\n",
      "y_pred_tensor: 陶喆\n",
      "y_test_tensor: 林俊杰 - 她说.mp3.csv\n",
      "y_pred_tensor: 林俊杰\n",
      "y_test_tensor: 林俊杰 - 学不会.mp3.csv\n",
      "y_pred_tensor: 王菲\n",
      "y_test_tensor: 王菲 - 当时的月亮.mp3.csv\n",
      "y_pred_tensor: 陶喆\n",
      "y_test_tensor: 陶喆 - 黑色柳丁.mp3.csv\n"
     ]
    }
   ],
   "source": [
    "all_NN_acc, all_NN_param = NN_Search(X, y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can draw a chart to compare their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------------------+\n",
      "| Model   | Parameters                |\n",
      "+=========+===========================+\n",
      "| S SVM   | {'C': 1, 'kernel': 'rbf'} |\n",
      "+---------+---------------------------+\n",
      "| S NN    | (32, 30, 32)              |\n",
      "+---------+---------------------------+\n",
      "| M SVM   | {'C': 1, 'kernel': 'rbf'} |\n",
      "+---------+---------------------------+\n",
      "| M NN    | (256, 30, 32)             |\n",
      "+---------+---------------------------+\n",
      "| E SVM   | {'C': 1, 'kernel': 'rbf'} |\n",
      "+---------+---------------------------+\n",
      "| E NN    | (128, 20, 64)             |\n",
      "+---------+---------------------------+\n",
      "| All SVM | {'C': 1, 'kernel': 'rbf'} |\n",
      "+---------+---------------------------+\n",
      "| All NN  | (16, 30, 32)              |\n",
      "+---------+---------------------------+\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Accuracy values\n",
    "accuracy_values = [start_SVM_acc, start_NN_acc, mid_SVM_acc, mid_NN_acc, end_SVM_acc, end_NN_acc, all_SVM_acc, all_NN_acc]\n",
    "\n",
    "# Model names\n",
    "model_names = ['S SVM', 'S NN', 'M SVM', 'M NN', 'E SVM', 'E NN', 'All SVM', 'All NN']\n",
    "\n",
    "# Parameters\n",
    "parameters = [start_SVM_param, start_NN_param, mid_SVM_param, mid_NN_param, end_SVM_param, end_NN_param, all_SVM_param, all_NN_param]\n",
    "\n",
    "# Create a table of model names and parameters\n",
    "table = []\n",
    "for name, param in zip(model_names, parameters):\n",
    "    table.append([name, param])\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(table, headers=['Model', 'Parameters'], tablefmt='grid'))\n",
    "\n",
    "# Plot the bar graph\n",
    "plt.bar(model_names, accuracy_values)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy of Different Models')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
